# Mini QA System using Pretrained Transformer

## Overview
This project demonstrates a **Question Answering (QA) system** that uses a **pretrained Transformer model (DistilBERT)** from Hugging Face.  
It is designed to read a paragraph from the **education** domain and provide accurate answers to questions asked about it.

The system applies the concept of **extractive question answering**, where the model identifies and extracts the most relevant span of text from the given passage as the answer.  
It shows how modern NLP models can comprehend context and reason over text without additional training.

---

## Real-World Relevance
Transformer-based QA systems form the core of many **intelligent applications** today, including:
- **Chatbots and digital assistants** that answer user queries.
- **Educational platforms** providing automated reading comprehension.
- **Customer support systems** that retrieve relevant information instantly.
- **Search engines** that return direct, context-aware answers.

This project represents how such technology can be adapted to domain-specific tasks like education, where models can assist in interactive learning and automated assessments.

---

## Example Questions

Below are some simple example questions you can try with the paragraph on *Modern Education*:


- *What is the main challenge in modern education?*  
- *How do adaptive learning systems help students?*  
- *Why is equity an important issue in education?*   
- *Why is lifelong learning becoming essential?*  



